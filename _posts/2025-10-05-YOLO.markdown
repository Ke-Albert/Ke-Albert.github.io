# YOLO-目标检测

TLTR
1-学习YOLO的过程
2-Andrew Ng深度学习课程中关于YOLO的讲解
3-霹雳吧啦Wz的讲解，https://www.bilibili.com/video/BV1yi4y1g7ro/

## 学习YOLO的过程

我是从25年7月份正式开始学习YOLO目标检测算法的，在这之前听了吴恩达深度学习课程中的关于YOLO的讲解，但是当时没有听懂，所以相当于重新开始。学习的是霹雳吧啦Wz的讲解，首先介绍了目标检测算法的两个方案：two-stage和one-stage。two-stage的方案包括先验框预测和分类器，代表是Faster R-CNN，而one-stage的方案则是直接预测目标框和分类，代表是YOLO，以及DETR等结合了注意力机制的模型，不过我现在主要是学习YOLO，DETR没有接触过。学习了YOLOv1-v3，其中YOLO-V3还有一个SPP的版本，这也是我跟随学习代码实现的版本，目前已经完成了YOLOV3-SPP的源码学习。当然，在这中间我还穿插着复习过Andrew Ng深度学习中涉及到的YOLO知识， `[还发现了别人总结好的网页](http://www.ai-start.com/dl2017/)`

## Andrew Ng 深度学习课程中关于YOLO的讲解
课程中，Andrew 首先将目标定位分解为了两个子问题：定位和分类。分类问题很简单，判断输入的图片中的物体是什么类型，将分类和定位结合起来，除了要判断物体的类型，还要判断物体的位置，这两个问题都是适用于单一目标，即每个图片中只有一个目标。进一步提出目标检测，图中存在着多个目标，我们都需要将它们分类和定位，这是一个多目标问题。
接着从分类的输出中，扩充定位信息，普通的分类输出是一个经过softmax的向量，对应物体的类别数量，需要定位我们只需要在输出中额外增加4个值，用来表示物体的边框信息。有了输出，我们需要定位监督学习的目标标签，目标标签是一个向量，包括一个Pc用来表示是否含有对象（可以理解为置信度），4个表示边框的值，物体类别数量的值，在物体类别中还可以使用一个值来表示，这个值从1-n变化。
Andrew 将4个边框值的表示扩充到了特征点检测问题，广义上神经网络可以输出图片上特征点的坐标，在目标检测中输出4个值表示边框信息，需要检测特征点可以设置任意需要统一输出特征点的数量，然后制作目标标签进行训练。
### 基于滑动窗口的目标检测算法
对图片进行裁剪，以识别汽车为例，只保留包含汽车的区域，其它区域裁剪掉，然后对裁剪后的图片进行分类，判断是否为汽车，输出y=0|1，这样就训练出了一个分类网络，对于多类别的同理输出y=0|1|...|n。网络训练好之后就可以基于滑动窗口来实现目标检测了，其中的定位问题，在滑动的时候就已经内含在其中了，即只要在当前窗口中识别出了一个类别，那么这个窗口的位置就是该类别的位置，我们可以记录窗口的横向和纵向滑动距离。滑动窗口的实现很灵活，首先可以选择是否以要重叠，即下一次的滑动是否与本次的部分区域重叠，从图上左上角向右下滑动，通过步距进行控制。还可以控制滑动窗口的大小。总之，这些人为控制的操作都是为了有效识别出物体，比如有些物体可能会存在两次滑动窗口之间。
这也就引出了滑动窗口的问题：计算成本太高。如果用小步幅，无法准确定位图中的对象，如果用大步幅（包括多个目标），粗糙间隔会影响性能。
为了提高计算效率，将滑动窗口使用卷积来实现。你可能会想，之前的滑动窗口不就是基于卷积实现的吗？再仔细分析下，最初的滑动窗口首先通过卷积判断当前窗口中有没有待分类的物体，至于滑动窗口的移动和卷积没有一点关系，可以通过两层循环实现这个逻辑。而这里的滑动窗口的卷积实现，是指将滑动窗口的移动步骤也以卷积的方式内含实现，在卷积的过程中就相当于移动了滑动窗口，过程不同但是在结果上是等价的，以至于我们可以理解为就像移动了窗口，但这是利用了卷积计算原理和它的高效操作实现的，因为卷积窗口也是需要滑动的，不过这个滑动是在pytorh等深度学习框架中实现了的，借助了GPU的高性能计算，就是说这个滑动是优化过的，提出该方法的论文是Sermanet, Pierre, et al. "OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks." Eprint Arxiv (2013)。其实就是将一维的全连接层替换成了多维的表示，不过这个多维表示也就表明它可以在其它维度上增加数量，从而将输出的特征层1x1xN变成mxmxn。该卷积操作的原理就是我们不需要把图像分割成子集，分别执行前向传播，而是将图像整体输入给卷积网络计算，其中有许多区域可以共享计算，最终得到输出层。换个角度就是感受野的解释，我们通过控制步距，窗口大小（这里的窗口大小不是卷积层的窗口大小，而是滑动窗口的大小，也就是在还没有使用卷积实现滑动窗口的时候，滑动窗口的大小，而这时我们可以去调整卷积层的大小，固定后，即卷积层大小固定，滑动窗口大小固定后，可以使用卷积的形式实现滑动窗口），来实现不同的下采样，在最后的输出结果中我们就可以得到感受野，最后输出的特征层大小就是相当于我们滑动了多少次窗口，它的位置映射回原图上就是目标框看的区域内容。
但是该算法仍然存在不能完美定位的问题，比如目标跨过多个区域时，一个窗口定位只能定位到部分区域，还有些目标更适合用长方形的框来定位。
### YOLO
YOLO算法其实也是根据感受野的解释反推在原图上的目标框位置，不过它输出了边框参数，所以在边框的形状上可以很灵活的变化学习。将原图划分成SxS个小区域，这SxS个小区域在原图上经过卷积网络后得到的输出层大小就是SxS(pixel)，所以YOLO预先定义输出层大小，通过控制输出层的尺寸来控制细粒度，以更好地识别目标。对于这SxS个输出，每个位置都包括一些参数(Pc,boxes-info,class)，通过构建对应的目标标签进行训练这样的一个目标检测网络。
这只是网络的原理，还需要结合额外的人为控制才能更好地训练网络，使用预测的边框。交并比、非极大值抑制、Pc阈值、Anchor-box。
Andrew 介绍的YOLO算法令人恍然大悟，但是对于其中的细节没有深入探究，代码部分的实战只是简单的实现，没有关于训练的部分内容，比如数据集处理、损失函数计算、正负样本选取这些。为了识别同一区域内的多个目标，增加了anchor box后，怎么确定哪个anchor box预测的是正确的，怎么根据anchor box来计算损失，这些问题没有解答。
## YOLOV3-SPP源码实战
从最初的YOLOV1开始，就已经有了很多的版本，比如YOLOV2、YOLOV3、YOLOV4等，每个版本都有自己的改进，比如SPP、FPN、PAN等。而YOLOV3-SPP是在YOLOV3的基础上，增加了SPP层，用来提取不同尺度的特征，这也是我跟随学习代码实现的版本。
学习路线首先是定义网络结构，为了让网络具有扩展性，将网络结构存储在了.cfg文件中，通过读取.cfg文件来定义网络结构，这也是YOLO系列的一个特点。有了网络结构，需要解析网络结构，将其转为在内存中规则的数据结构，再根据这个数据结构来搭建网络模型。网络模型搭建好后，训练时需要导入数据集，就需要自己制作数据集入口，包括一系列的检查文件路径、预处理、缓存操作等，都定义在了一个类里面，通过继承pytorch的`Dataset`类，传入dataloader中。数据集加载后就是训练，每个批次经过网络输出，得到预测值，需要计算预测值与关联标签的损失，再反向传播，反向传播时又定义了调度器，学习率衰减规则，打印日志等模块内容，等等这些构成了YOLOV3-SPP算法的全部过程。在训练时，除了损失计算部分是与YOLO强关联外，其它的内容都是可以迁移通用的，比如调度器、日志打印模块。
### .cfg网络定义
.cfg网络定义内容其实就是一些规则结构的字符串，描述了网络的层结构。并搭配了对应的解析器，用来解析.cfg文件，将其转为在内存中规则的数据结构。它主要有convolutional层，shortcut层，池化层、route层、upsample层、YOLO层。其中shortcut层和route层需要特别注意，不像其它层需要做具体的工作（比如进行大量计算），这两个层之所以单独独立成一个层（在编号中占据一个位置），shortcut层负责残差连接，所以它的关键字`from`经常等于-3，以当前shortcut层为索引0，向其上层索引3个，route层有两个作用，拼接多个层的输出和将当前的指针（代表网络当前输出所处的位置）退回到某一层（在SPP的输入多分支时有用），这是因为网络定义的顺序是线性的，即使平行结构的SPP，也需要按照线性顺序排序。YOLO层不是预测头所处的层，它是预测头的下一层（紧连着预测头），它的作用是初始化anchor模板，定义特征层的网格，判断训练还是预测，从而输出不同的结果。
### 自定义数据集
数据集集中了对图片和标签载入的操作预处理。包括设置批量大小，设置预处理输出图片大小、数据缓存、是否进行数据增强等操作。
### 损失计算
正样本计算目标框损失、分类损失和置信度损失，负样本只计算置信度损失。在`compute_loss`函数中，根据预测值和关联标签，计算损失。首先根据预测值和关联标签，筛选出正样本，也即在`build_target`函数中，筛选出正样本的类别标签（用于计算类别损失）、正样本对应的gt box信息、含有正样本的图像索引、anchor模板索引、所处的哪一个grid位置信息、anchor模板的大小信息，遍历每一个YOLO输出层，计算这三个损失。其中，置信度损失计算时首先会创建一个tobj，初始值都为0，之后对于筛选出来的正样本，根据正样本计算的iou值动态（每个批次正样本会变）去得到一个标签置信度并在tobj对应的正样本位置填上该值，其它未变的即为负样本的默认值0，然后使用预测的值和tobj进行二值交叉熵计算，得到置信度损失。可以注意到，这里并没有按照正负样本按照一定比例选取，而是计算了全部的负样本，不过使用了Focal loss、调整置信度权重等方式有效地缓解了正负样本不平衡的问题。
